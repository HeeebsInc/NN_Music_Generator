{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "from keras.models import load_model\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G4' 'D4' 'B3' 'G3' 'G4' 'E4' 'B3' 'E3' 'A4' 'F#4' 'D4' 'D3' 'B4' 'G4'\n",
      " 'D4' 'G3' 'C5' 'C4' 'A3' 'D5' 'B3' 'B3' 'D5' 'G4' 'B3' 'G3' 'D5' 'E4'\n",
      " 'A3' 'A3' 'C#5' 'E4' 'A3' 'A2' 'D5' 'F#4' 'A3' 'D3' 'B4' 'G4' 'G3' 'G3'\n",
      " 'C5' 'E4' 'G3' 'C3' 'B4' 'D4' 'G3' 'G2']\n",
      "[901, 166, 1322, 346, 901, 1200, 1322, 389, 1656, 350, 166, 999, 344, 901, 166, 346, 208, 1669, 316, 857, 1322, 1322, 857, 901, 1322, 346, 857, 1200, 316, 316, 173, 1200, 316, 780, 857, 350, 316, 999, 344, 901, 346, 346, 208, 1200, 346, 1606, 344, 166, 346, 380]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Music With Neural Network: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:22<00:00, 44.64it/s]\n"
     ]
    }
   ],
   "source": [
    "#WITHOUT INSTRUMNET\n",
    "def read_ts_midi(file_path, timestep): \n",
    "    notes = [] \n",
    "    notes_to_parse = None \n",
    "\n",
    "\n",
    "    midi= converter.parse(file_path)\n",
    "\n",
    "    s2 = instrument.partitionByInstrument(midi)\n",
    "    for part in s2.parts:\n",
    "#         if 'Piano' in str(part): \n",
    "\n",
    "        notes_to_parse = part.recurse() \n",
    "\n",
    "        #finding whether a particular element is note or a chord\n",
    "        for element in notes_to_parse:\n",
    "\n",
    "            #note\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "\n",
    "            #chord\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "    notes = np.array(notes)\n",
    "#     np.random.shuffle(notes)\n",
    "    return notes[:timestep]\n",
    "\n",
    "        \n",
    "def get_pickles(pick_name): \n",
    "    x_train, x_test, y_train, y_test, notes_dict = pickle.load(open(f'../Pickles/{pick_name}', 'rb'))\n",
    "    return x_train, x_test, y_train, y_test, notes_dict\n",
    "\n",
    "\n",
    "\n",
    "def convert_to_midi(prediction_output, filename):\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                output_notes.append(instrument.SnareDrum())\n",
    "                cn=current_note\n",
    "                new_note = note.Note(cn)\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        else:\n",
    "            output_notes.append(instrument.SnareDrum())\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "#             new_note.storedInstrument = instrument.Violin()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += .5\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp=filename)\n",
    "\n",
    "\n",
    "def generate_music(model, first_sequence, timestep = 50, total_runs = 50):\n",
    "    song = [i for i in first_sequence]\n",
    "    total_iter = 0\n",
    "    current_idx = 0\n",
    "    pbar = tqdm(desc= 'Creating Music With Neural Network', total = total_runs)\n",
    "    while total_iter < total_runs:\n",
    "        current_seq = song[current_idx: timestep+current_idx]\n",
    "        current_seq = np.array(current_seq).reshape(1, timestep, 1)\n",
    "        next_note = np.argmax(model.predict(current_seq)[0])\n",
    "        song.append(next_note)\n",
    "        total_iter += 1 \n",
    "        current_idx += 1\n",
    "        pbar.update(1)\n",
    "    \n",
    "    return song\n",
    "\n",
    "# #Random generated\n",
    "# test_type = 'Tester'\n",
    "# x_train, x_test, y_train, y_test, notes_dict = get_pickles(f'{test_type}.p')\n",
    "# reverse_notes = {n:idx for idx, n in notes_dict.items()}\n",
    "# first_seq = np.random.randint(0, len(reverse_notes), size = 50)\n",
    "# model = load_model(f'ModelWeights/LSTM_{test_type}.h5')\n",
    "\n",
    "# new_song = generate_music(model, first_seq, total_runs = 50)\n",
    "# new_song_notes = [notes_dict[i] for i in new_song]\n",
    "    \n",
    "# convert_to_midi(new_song_notes, filename = f'Tests/{test_type}.mid')\n",
    "    \n",
    "    \n",
    "# first sequence from a song \n",
    "test_type = 'Tester'\n",
    "x_train, x_test, y_train, y_test, notes_dict = get_pickles(f'{test_type}.p')\n",
    "reverse_notes = {n:idx for idx, n in notes_dict.items()}\n",
    "first_seq = read_ts_midi('../Classical/004311b_.mid', timestep = 50)\n",
    "print(first_seq)\n",
    "first_seq = [reverse_notes[i] for i in first_seq]\n",
    "print(first_seq)\n",
    "model = load_model(f'ModelWeights/LSTM_{test_type}.h5')\n",
    "\n",
    "new_song = generate_music(model, first_seq, total_runs = 300)\n",
    "new_song_notes = [notes_dict[i] for i in new_song]\n",
    "    \n",
    "convert_to_midi(new_song_notes, filename = f'Tests/{test_type}.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WITH INSTRUMENT\n",
    "def read_ts_midi(file_path, timestep): \n",
    "    notes = [] \n",
    "    notes_to_parse = None \n",
    "    instruments = []\n",
    "\n",
    "    midi= converter.parse(file_path)\n",
    "    \n",
    "    s2 = instrument.partitionByInstrument(midi)\n",
    "    for part in s2.parts:\n",
    "        str_part = str(part)\n",
    "        if str_part == '<music21.stream.Part>': \n",
    "            continue \n",
    "        else:\n",
    "            cutoff_len = len('<music21.stream.Part ') \n",
    "            instru = str_part[cutoff_len:]\n",
    "            instru = instru[:instru.find('>')]\n",
    "            notes_to_parse = part.recurse() \n",
    "            for element in notes_to_parse: \n",
    "                if isinstance(element, note.Note): \n",
    "                    notes.append(str(element.pitch))\n",
    "                    instruments.append(instru)\n",
    "                elif isinstance(element, chord.Chord): \n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))      \n",
    "                    instruments.append(instru)\n",
    "                    \n",
    "    return np.array(list(zip(instruments, notes)))\n",
    "        \n",
    "def get_pickles(pick_name): \n",
    "    x_train, x_test, y_train, y_test, notes_dict = pickle.load(open(f'../Pickles/{pick_name}', 'rb'))\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test, notes_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_music(model, first_sequence, timestep = 10, total_runs = 25):\n",
    "    song = [i for i in first_sequence]\n",
    "    total_iter = 0\n",
    "    current_idx = 0\n",
    "    while total_iter < total_runs: \n",
    "        current_seq = song[current_idx: timestep+current_idx]\n",
    "        current_seq = np.array(current_seq).reshape(1, timestep, 1)\n",
    "        next_note = np.argmax(model.predict(current_seq)[0])\n",
    "        song.append(next_note)\n",
    "        total_iter += 1 \n",
    "        current_idx += 1\n",
    "    \n",
    "    return song\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test, notes_dict = get_pickles('50cent.p')\n",
    "reverse_notes = {n:idx for idx, n in notes_dict.items()}\n",
    "first_seq = read_ts_midi('../50Cent/50_cent-piggy_bank.mid', timestep = 10)\n",
    "first_seq = [' '.join(i) for i in first_seq]\n",
    "first_seq = [reverse_notes[i] for i in first_seq]\n",
    "model = load_model('ModelWeights/LSTM.h5')\n",
    "\n",
    "new_song = generate_music(model, first_seq)\n",
    "new_song_notes = [notes_dict[i] for i in new_song]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_song_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(prediction_output):\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for ints_note in prediction_output:\n",
    "        ints_note_split = ints_note.split(' ')\n",
    "        pattern = ints_note_split[-1]\n",
    "        instru = ' '.join(ints_note_split[:-1])\n",
    "        print(instru)\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                output_notes.append(instrument.Instrument(instrumentName = instru))\n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "#                 new_note.storedInstrument = instrument.Violin()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            output_notes.append(instrument.Instrument(instrumentName = instru))\n",
    "\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "#             new_note.storedInstrument = instrument.Violin()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += .5\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='music.mid')\n",
    "    \n",
    "convert_to_midi(new_song_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(new_song_notes)\n",
    "print(new_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(0, len(x_test)-1)\n",
    "random_music = x_test[idx]\n",
    "predictions = [] \n",
    "for i in range(10): \n",
    "    random_music = random_music.reshape(1,timestep,1)\n",
    "    prob = lstm_model.predict(random_music)[0]\n",
    "    y_pred = np.argmax(prob, axis = 0)\n",
    "    \n",
    "    predictions.append(y_pred)\n",
    "    \n",
    "    random_music = np.insert(random_music[0], len(random_music[0]),y_pred)\n",
    "    random_music = random_music[1:]\n",
    "    \n",
    "print(predictions)\n",
    "\n",
    "unique_x = list(set(x.ravel()))\n",
    "\n",
    "x_int_dict = dict((i,n) for n,i in enumerate(unique_x))\n",
    "\n",
    "predicted_notes = [x_int_dict[i] for i in predictions]\n",
    "predicted_notes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MusicGenerator",
   "language": "python",
   "name": "musicgenerator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
