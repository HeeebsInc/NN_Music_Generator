{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, Dense, Conv1D, Dropout, GlobalMaxPool1D\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2004, 10, 1) (2004,)\n",
      "(175, 10, 1) (175,)\n"
     ]
    }
   ],
   "source": [
    "model_type = 'EDM'\n",
    "def get_pickles(pick_name): \n",
    "    x_train, x_test, y_train, y_test, notes_dict = pickle.load(open(f'../Pickles/{pick_name}', 'rb'))\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test, notes_dict\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test, notes_dict = get_pickles(f'{model_type}.p')\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = x_train[:5001]\n",
    "# y_train = y_train[:5001]\n",
    "# x_test = x_test[:5001]\n",
    "# y_test = y_test[:5001]\n",
    "# print(x_train.shape, y_train.shape)\n",
    "# print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm(n): \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, return_sequences = True))\n",
    "    model.add(LSTM(256))\n",
    "    model.add(Dropout(.25))\n",
    "    model.add(Dense(512, activation = 'relu'))\n",
    "    model.add(Dropout(.25))\n",
    "    model.add(Dense(n, activation = 'softmax')) \n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_lstm(n): \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences = True))\n",
    "    model.add(LSTM(128))    \n",
    "#     model.add(Dense(128, activation = 'relu'))\n",
    "#     model.add(Dropout(.3))\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "#     model.add(Dense(512, activation = 'relu'))\n",
    "\n",
    "    model.add(Dropout(.3))\n",
    "    model.add(Dense(n, activation = 'softmax')) \n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"opencl_amd_ellesmere.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2004 samples, validate on 175 samples\n",
      "Epoch 1/1000\n",
      "2004/2004 [==============================] - 24s 12ms/step - loss: 5.5842 - acc: 0.0070 - val_loss: 5.2724 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.27236, saving model to ModelWeights/LSTM_EDM.h5\n",
      "Epoch 2/1000\n",
      "2004/2004 [==============================] - 0s 214us/step - loss: 5.1984 - acc: 0.0145 - val_loss: 5.1869 - val_acc: 0.0400\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.27236 to 5.18690, saving model to ModelWeights/LSTM_EDM.h5\n",
      "Epoch 3/1000\n",
      "2004/2004 [==============================] - 0s 209us/step - loss: 5.1044 - acc: 0.0135 - val_loss: 5.1709 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss improved from 5.18690 to 5.17093, saving model to ModelWeights/LSTM_EDM.h5\n",
      "Epoch 4/1000\n",
      "2004/2004 [==============================] - 0s 214us/step - loss: 5.0545 - acc: 0.0170 - val_loss: 5.1365 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss improved from 5.17093 to 5.13647, saving model to ModelWeights/LSTM_EDM.h5\n",
      "Epoch 5/1000\n",
      "2004/2004 [==============================] - 0s 216us/step - loss: 4.9983 - acc: 0.0190 - val_loss: 5.1192 - val_acc: 0.0057\n",
      "\n",
      "Epoch 00005: val_loss improved from 5.13647 to 5.11917, saving model to ModelWeights/LSTM_EDM.h5\n",
      "Epoch 6/1000\n",
      "2004/2004 [==============================] - 0s 212us/step - loss: 4.9567 - acc: 0.0195 - val_loss: 5.0937 - val_acc: 0.0057\n",
      "\n",
      "Epoch 00006: val_loss improved from 5.11917 to 5.09366, saving model to ModelWeights/LSTM_EDM.h5\n",
      "Epoch 7/1000\n",
      "2004/2004 [==============================] - 0s 210us/step - loss: 4.9090 - acc: 0.0225 - val_loss: 5.0977 - val_acc: 0.0057\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 5.09366\n",
      "Epoch 8/1000\n",
      "2004/2004 [==============================] - 0s 211us/step - loss: 4.8822 - acc: 0.0210 - val_loss: 5.0737 - val_acc: 0.0229\n",
      "\n",
      "Epoch 00008: val_loss improved from 5.09366 to 5.07369, saving model to ModelWeights/LSTM_EDM.h5\n",
      "Epoch 9/1000\n",
      "2004/2004 [==============================] - 0s 212us/step - loss: 4.8138 - acc: 0.0240 - val_loss: 5.0666 - val_acc: 0.0171\n",
      "\n",
      "Epoch 00009: val_loss improved from 5.07369 to 5.06657, saving model to ModelWeights/LSTM_EDM.h5\n",
      "Epoch 10/1000\n",
      "2004/2004 [==============================] - 0s 210us/step - loss: 4.7795 - acc: 0.0324 - val_loss: 5.0249 - val_acc: 0.0343\n",
      "\n",
      "Epoch 00010: val_loss improved from 5.06657 to 5.02487, saving model to ModelWeights/LSTM_EDM.h5\n",
      "Epoch 11/1000\n",
      "2004/2004 [==============================] - 0s 211us/step - loss: 4.7115 - acc: 0.0264 - val_loss: 5.0176 - val_acc: 0.0457\n",
      "\n",
      "Epoch 00011: val_loss improved from 5.02487 to 5.01765, saving model to ModelWeights/LSTM_EDM.h5\n",
      "Epoch 12/1000\n",
      "2004/2004 [==============================] - 0s 211us/step - loss: 4.6237 - acc: 0.0389 - val_loss: 4.9739 - val_acc: 0.0343\n",
      "\n",
      "Epoch 00012: val_loss improved from 5.01765 to 4.97394, saving model to ModelWeights/LSTM_EDM.h5\n",
      "Epoch 13/1000\n",
      "2004/2004 [==============================] - 0s 213us/step - loss: 4.5775 - acc: 0.0429 - val_loss: 4.9346 - val_acc: 0.0571\n",
      "\n",
      "Epoch 00013: val_loss improved from 4.97394 to 4.93462, saving model to ModelWeights/LSTM_EDM.h5\n",
      "Epoch 14/1000\n",
      "2004/2004 [==============================] - 0s 213us/step - loss: 4.4600 - acc: 0.0554 - val_loss: 4.9202 - val_acc: 0.0514\n",
      "\n",
      "Epoch 00014: val_loss improved from 4.93462 to 4.92017, saving model to ModelWeights/LSTM_EDM.h5\n",
      "Epoch 15/1000\n",
      "2004/2004 [==============================] - 0s 211us/step - loss: 4.3710 - acc: 0.0534 - val_loss: 4.9139 - val_acc: 0.0686\n",
      "\n",
      "Epoch 00015: val_loss improved from 4.92017 to 4.91392, saving model to ModelWeights/LSTM_EDM.h5\n",
      "Epoch 16/1000\n",
      "2004/2004 [==============================] - 0s 213us/step - loss: 4.2728 - acc: 0.0589 - val_loss: 4.8796 - val_acc: 0.0457\n",
      "\n",
      "Epoch 00016: val_loss improved from 4.91392 to 4.87959, saving model to ModelWeights/LSTM_EDM.h5\n",
      "Epoch 17/1000\n",
      "2004/2004 [==============================] - 0s 212us/step - loss: 4.1779 - acc: 0.0689 - val_loss: 4.8939 - val_acc: 0.0686\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 4.87959\n",
      "Epoch 18/1000\n",
      "2004/2004 [==============================] - 0s 212us/step - loss: 4.1116 - acc: 0.0704 - val_loss: 4.9197 - val_acc: 0.0857\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 4.87959\n",
      "Epoch 19/1000\n",
      "2004/2004 [==============================] - 0s 212us/step - loss: 4.0067 - acc: 0.0853 - val_loss: 4.8917 - val_acc: 0.0800\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 4.87959\n",
      "Epoch 20/1000\n",
      "2004/2004 [==============================] - 0s 217us/step - loss: 3.9175 - acc: 0.0903 - val_loss: 4.8850 - val_acc: 0.0914\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 4.87959\n",
      "Epoch 21/1000\n",
      "2004/2004 [==============================] - 0s 215us/step - loss: 3.8301 - acc: 0.0993 - val_loss: 4.9537 - val_acc: 0.0743\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 4.87959\n",
      "Epoch 22/1000\n",
      "2004/2004 [==============================] - 0s 219us/step - loss: 3.7385 - acc: 0.1093 - val_loss: 4.9239 - val_acc: 0.0914\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 4.87959\n",
      "Epoch 23/1000\n",
      "2004/2004 [==============================] - 0s 211us/step - loss: 3.6646 - acc: 0.1193 - val_loss: 4.9801 - val_acc: 0.0686\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 4.87959\n",
      "Epoch 24/1000\n",
      "2004/2004 [==============================] - 0s 211us/step - loss: 3.5599 - acc: 0.1223 - val_loss: 5.0086 - val_acc: 0.0857\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 4.87959\n",
      "Epoch 25/1000\n",
      "2004/2004 [==============================] - 0s 218us/step - loss: 3.4735 - acc: 0.1362 - val_loss: 5.0270 - val_acc: 0.0971\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 4.87959\n",
      "Epoch 26/1000\n",
      "2004/2004 [==============================] - 0s 213us/step - loss: 3.3712 - acc: 0.1472 - val_loss: 5.0494 - val_acc: 0.0971\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 4.87959\n",
      "Epoch 00026: early stopping\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', verbose = 1, patience=10, min_delta = .00075)\n",
    "model_checkpoint = ModelCheckpoint(f'ModelWeights/LSTM_{model_type}.h5', verbose = 1, save_best_only=True,\n",
    "                                  monitor = 'val_loss')\n",
    "\n",
    "batch = 128 \n",
    "epochs = 1000 \n",
    "callbacks = [early_stopping, model_checkpoint]\n",
    "\n",
    "unique_n = len(notes_dict)\n",
    "lstm_model = get_lstm(unique_n)\n",
    "\n",
    "lstm_history = lstm_model.fit(x_train, y_train, batch_size = batch, epochs = epochs, validation_data = (x_test, y_test), \n",
    "                        callbacks = callbacks)\n",
    "\n",
    "pickle.dump(lstm_history, open(f'ModelPerf/{model_type}.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.save_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.system(r'%windir%\\system32\\rundll32.exe powrprof.dll,SetSuspendState Hibernate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MusicGenerator",
   "language": "python",
   "name": "musicgenerator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
