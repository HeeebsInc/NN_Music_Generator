{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21  \n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midi(file_path): \n",
    "    notes = [] \n",
    "    notes_to_parse = None \n",
    "    key = 0\n",
    "\n",
    "    try:\n",
    "        midi= music21.converter.parse(file_path)\n",
    "        key = midi.analyze('key')\n",
    "        s2 = music21.instrument.partitionByInstrument(midi)\n",
    "        for part in s2:\n",
    "            if 'Piano' in str(part): \n",
    "                notes_to_parse = s2.recurse()\n",
    "                for element in notes_to_parse:\n",
    "                #select elements of only piano\n",
    "                    if isinstance(element, music21.note.Note): \n",
    "                        notes.append(str(element.pitch))\n",
    "                    elif isinstance(element, music21.chord.Chord): \n",
    "                        notes.append('.'.join(str(n) for n in element.pitches))\n",
    "        return np.array(notes)\n",
    "    except: \n",
    "        return np.array([])\n",
    "\n",
    "\n",
    "def unique(np_array, array_type, unique_set): \n",
    "    unique_set_reverse = {n:idx for (idx, n) in unique_set.items()}\n",
    "    new_array =[] \n",
    "    if array_type == 'x':\n",
    "        for group in np_array: \n",
    "            temp = [] \n",
    "            for n in group: \n",
    "                temp.append(unique_set_reverse[n])\n",
    "            new_array.append(temp)\n",
    "    else: \n",
    "        for n in np_array: \n",
    "            new_array.append(unique_set_reverse[n])\n",
    "    new_array = np.array(new_array)\n",
    "    return new_array\n",
    "\n",
    "def remove_rare(note_array, note_count, min_count): \n",
    "    note_array = [i for i in note_array if note_count[i] >= min_count]\n",
    "    return np.array(note_array)\n",
    "\n",
    "def get_tts(base_dir, pick_name = None, sample_num= 1000, timestep = 50, min_count = 20): \n",
    "    song_files = [f'{base_dir}/{i}' for i in os.listdir(base_dir)][:sample_num]\n",
    "    songs_notes = [read_midi(i) for i in tqdm(song_files, desc = 'Reading Midi Files')]\n",
    "    songs_notes = [i for i in songs_notes if len(i) != 0]\n",
    "    all_notes = [i for note_ in songs_notes for i in note_]\n",
    "    note_counter = defaultdict(int)\n",
    "    for i in all_notes: \n",
    "        note_counter[i]+= 1\n",
    "    #remove rare words\n",
    "    songs_notes = [remove_rare(i, note_counter, min_count  = min_count) for i in songs_notes]\n",
    "    all_notes = [i for note_ in songs_notes for i in note_]\n",
    "    note_counter = defaultdict(int)\n",
    "    for i in all_notes: \n",
    "        note_counter[i]+= 1\n",
    "    all_notes_dict = {idx: n for idx, n in enumerate(set(all_notes))}\n",
    "    x = [] \n",
    "    y = [] \n",
    "\n",
    "    pbar = tqdm(songs_notes, desc = 'Creating Timeseries')\n",
    "    for idx_song, song in enumerate(pbar):\n",
    "        for idx in range(timestep,len(song)-(timestep), 1): \n",
    "            x.append(song[idx:idx+timestep])\n",
    "            y.append(song[idx + (timestep)])\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)  \n",
    "\n",
    "    new_x = unique(x, unique_set = all_notes_dict, array_type = 'x')\n",
    "    new_y = unique(y, unique_set = all_notes_dict, array_type ='y')\n",
    "    \n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(new_x, new_y, train_size = .92, random_state = 10)\n",
    "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1],1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], x_test.shape[1],1)\n",
    "    \n",
    "    if pick_name:\n",
    "        pick_tup= (x_train, x_test, y_train, y_test, all_notes_dict)\n",
    "        pickle.dump(pick_tup, open(f'../Pickles/{pick_name}', 'wb'), protocol = 4)\n",
    "                    \n",
    "    return x_train, x_test, y_train, y_test, all_notes_dict\n",
    "\n",
    "x_train, x_test, y_train, y_test, all_notes_dict = get_tts('../Classical', sample_num = 2000, pick_name= 'Classical1_1.p', \n",
    "                                                           min_count = 5, timestep = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Dense, Conv1D, Dropout, GlobalMaxPool1D\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'Classical1_1'\n",
    "def get_pickles(pick_name): \n",
    "    x_train, x_test, y_train, y_test, notes_dict = pickle.load(open(f'../Pickles/{pick_name}', 'rb'))\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test, notes_dict\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test, notes_dict = get_pickles(f'{model_type}.p')\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm(n): \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, return_sequences = True))\n",
    "    model.add(LSTM(256))    \n",
    "#     model.add(Dense(128, activation = 'relu'))\n",
    "#     model.add(Dropout(.3))\n",
    "    model.add(Dense(512, activation = 'relu'))\n",
    "#     model.add(Dense(512, activation = 'relu'))\n",
    "\n",
    "    model.add(Dropout(.3))\n",
    "    model.add(Dense(n, activation = 'softmax')) \n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', verbose = 1, patience=10, min_delta = .00075)\n",
    "model_checkpoint = ModelCheckpoint(f'ModelWeights/LSTM_{model_type}.h5', verbose = 1, save_best_only=True,\n",
    "                                  monitor = 'val_loss')\n",
    "\n",
    "batch = 32 \n",
    "epochs = 1000 \n",
    "callbacks = [early_stopping, model_checkpoint]\n",
    "\n",
    "unique_n = len(notes_dict)\n",
    "lstm_model = get_lstm(unique_n)\n",
    "\n",
    "#if you want to train from before\n",
    "# lstm_model = load_model(f'ModelWeights/LSTM_{model_type}.h5')\n",
    "\n",
    "lstm_history = lstm_model.fit(x_train, y_train, batch_size = batch, epochs = epochs, validation_data = (x_test, y_test), \n",
    "                        callbacks = callbacks)\n",
    "\n",
    "pickle.dump(lstm_history, open(f'ModelPerf/{model_type}.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.save_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.system(r'%windir%\\system32\\rundll32.exe powrprof.dll,SetSuspendState Hibernate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WITHOUT INSTRUMENT2\n",
    "def read_midi(file_path): \n",
    "    notes = [] \n",
    "    notes_to_parse = None \n",
    "    key = 0\n",
    "\n",
    "    try:\n",
    "        midi= music21.converter.parse(file_path)\n",
    "        key = midi.analyze('key')\n",
    "        s2 = music21.instrument.partitionByInstrument(midi)\n",
    "        for part in s2:\n",
    "            if 'Piano' in str(part): \n",
    "                notes_to_parse = s2.recurse()\n",
    "                for element in notes_to_parse:\n",
    "                #select elements of only piano\n",
    "                    if isinstance(element, music21.note.Note): \n",
    "                        notes.append(str(element.pitch))\n",
    "                    elif isinstance(element, music21.chord.Chord): \n",
    "                        notes.append('.'.join(str(n) for n in element.pitches))\n",
    "        return np.array(notes)\n",
    "    except: \n",
    "        raise\n",
    "        return np.array([])\n",
    "\n",
    "\n",
    "file = f'../midi_songs/FFIX_Piano.mid'\n",
    "\n",
    "read_midi(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MusicGenerator",
   "language": "python",
   "name": "musicgenerator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
