{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, Dense, Conv1D, Dropout, GlobalMaxPool1D\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(292618, 50, 1) (292618,)\n",
      "(25446, 50, 1) (25446,)\n"
     ]
    }
   ],
   "source": [
    "model_type = 'Classical'\n",
    "def get_pickles(pick_name): \n",
    "    x_train, x_test, y_train, y_test, notes_dict = pickle.load(open(f'../Pickles/{pick_name}', 'rb'))\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test, notes_dict\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test, notes_dict = get_pickles(f'{model_type}.p')\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = x_train[:5001]\n",
    "# y_train = y_train[:5001]\n",
    "# x_test = x_test[:5001]\n",
    "# y_test = y_test[:5001]\n",
    "# print(x_train.shape, y_train.shape)\n",
    "# print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm(n): \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, return_sequences = True))\n",
    "    model.add(LSTM(256))\n",
    "    model.add(Dropout(.25))\n",
    "    model.add(Dense(512, activation = 'relu'))\n",
    "    model.add(Dropout(.25))\n",
    "    model.add(Dense(n, activation = 'softmax')) \n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_lstm(n): \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, return_sequences = True))\n",
    "    model.add(LSTM(128))    \n",
    "#     model.add(Dense(128, activation = 'relu'))\n",
    "#     model.add(Dropout(.3))\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "#     model.add(Dense(512, activation = 'relu'))\n",
    "\n",
    "    model.add(Dropout(.3))\n",
    "    model.add(Dense(n, activation = 'softmax')) \n",
    "    model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"opencl_amd_ellesmere.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 292618 samples, validate on 25446 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 2266 of 9875 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 7732 of 9875 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292608/292618 [============================>.] - ETA: 0s - loss: 3.8118 - acc: 0.0523"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 2880 of 9875 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 8327 of 9875 operations complete\n",
      "INFO:plaidml:Analyzing Ops: 3616 of 4238 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292618/292618 [==============================] - 233s 797us/step - loss: 3.8118 - acc: 0.0523 - val_loss: 3.8471 - val_acc: 0.0540\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.84714, saving model to ModelWeights/LSTM_Classical.h5\n",
      "Epoch 2/1000\n",
      "292618/292618 [==============================] - 178s 607us/step - loss: 3.7812 - acc: 0.0529 - val_loss: 3.8209 - val_acc: 0.0560\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.84714 to 3.82091, saving model to ModelWeights/LSTM_Classical.h5\n",
      "Epoch 3/1000\n",
      "292618/292618 [==============================] - 174s 593us/step - loss: 3.7474 - acc: 0.0543 - val_loss: 3.8079 - val_acc: 0.0520\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.82091 to 3.80788, saving model to ModelWeights/LSTM_Classical.h5\n",
      "Epoch 4/1000\n",
      "292618/292618 [==============================] - 173s 592us/step - loss: 3.7154 - acc: 0.0549 - val_loss: 3.7837 - val_acc: 0.0569\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.80788 to 3.78369, saving model to ModelWeights/LSTM_Classical.h5\n",
      "Epoch 5/1000\n",
      "292618/292618 [==============================] - 174s 594us/step - loss: 3.6863 - acc: 0.0558 - val_loss: 3.7773 - val_acc: 0.0532\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.78369 to 3.77734, saving model to ModelWeights/LSTM_Classical.h5\n",
      "Epoch 6/1000\n",
      "292618/292618 [==============================] - 174s 593us/step - loss: 3.6592 - acc: 0.0567 - val_loss: 3.7806 - val_acc: 0.0567\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.77734\n",
      "Epoch 7/1000\n",
      "292618/292618 [==============================] - 173s 590us/step - loss: 3.6349 - acc: 0.0581 - val_loss: 3.7382 - val_acc: 0.0564\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.77734 to 3.73824, saving model to ModelWeights/LSTM_Classical.h5\n",
      "Epoch 8/1000\n",
      "292618/292618 [==============================] - 174s 596us/step - loss: 3.6127 - acc: 0.0589 - val_loss: 3.7229 - val_acc: 0.0563\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.73824 to 3.72289, saving model to ModelWeights/LSTM_Classical.h5\n",
      "Epoch 9/1000\n",
      "292618/292618 [==============================] - 174s 593us/step - loss: 3.5899 - acc: 0.0590 - val_loss: 3.7223 - val_acc: 0.0599\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.72289 to 3.72230, saving model to ModelWeights/LSTM_Classical.h5\n",
      "Epoch 10/1000\n",
      "292618/292618 [==============================] - 173s 593us/step - loss: 3.5714 - acc: 0.0595 - val_loss: 3.7222 - val_acc: 0.0579\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.72230 to 3.72222, saving model to ModelWeights/LSTM_Classical.h5\n",
      "Epoch 11/1000\n",
      "292618/292618 [==============================] - 173s 591us/step - loss: 3.5528 - acc: 0.0605 - val_loss: 3.7261 - val_acc: 0.0577\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.72222\n",
      "Epoch 12/1000\n",
      "292618/292618 [==============================] - 174s 595us/step - loss: 3.5349 - acc: 0.0615 - val_loss: 3.7005 - val_acc: 0.0607\n",
      "\n",
      "Epoch 00012: val_loss improved from 3.72222 to 3.70049, saving model to ModelWeights/LSTM_Classical.h5\n",
      "Epoch 13/1000\n",
      "292618/292618 [==============================] - 173s 590us/step - loss: 3.5200 - acc: 0.0621 - val_loss: 3.6897 - val_acc: 0.0600\n",
      "\n",
      "Epoch 00013: val_loss improved from 3.70049 to 3.68971, saving model to ModelWeights/LSTM_Classical.h5\n",
      "Epoch 14/1000\n",
      "292618/292618 [==============================] - 174s 593us/step - loss: 3.5018 - acc: 0.0630 - val_loss: 3.6862 - val_acc: 0.0611\n",
      "\n",
      "Epoch 00014: val_loss improved from 3.68971 to 3.68618, saving model to ModelWeights/LSTM_Classical.h5\n",
      "Epoch 15/1000\n",
      "292618/292618 [==============================] - 174s 594us/step - loss: 3.4866 - acc: 0.0629 - val_loss: 3.6959 - val_acc: 0.0574\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.68618\n",
      "Epoch 16/1000\n",
      "292618/292618 [==============================] - 177s 607us/step - loss: 3.4757 - acc: 0.0630 - val_loss: 3.6998 - val_acc: 0.0608\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.68618\n",
      "Epoch 17/1000\n",
      "292618/292618 [==============================] - 173s 591us/step - loss: 3.4610 - acc: 0.0642 - val_loss: 3.6872 - val_acc: 0.0604\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.68618\n",
      "Epoch 18/1000\n",
      "292618/292618 [==============================] - 172s 589us/step - loss: 3.4465 - acc: 0.0647 - val_loss: 3.6740 - val_acc: 0.0620\n",
      "\n",
      "Epoch 00018: val_loss improved from 3.68618 to 3.67397, saving model to ModelWeights/LSTM_Classical.h5\n",
      "Epoch 19/1000\n",
      "292618/292618 [==============================] - 172s 588us/step - loss: 3.4348 - acc: 0.0650 - val_loss: 3.6834 - val_acc: 0.0604\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.67397\n",
      "Epoch 20/1000\n",
      "292618/292618 [==============================] - 172s 588us/step - loss: 3.4237 - acc: 0.0655 - val_loss: 3.6798 - val_acc: 0.0602\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.67397\n",
      "Epoch 21/1000\n",
      "292618/292618 [==============================] - 172s 588us/step - loss: 3.4135 - acc: 0.0654 - val_loss: 3.6834 - val_acc: 0.0628\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.67397\n",
      "Epoch 22/1000\n",
      "292618/292618 [==============================] - 172s 588us/step - loss: 3.4043 - acc: 0.0660 - val_loss: 3.6850 - val_acc: 0.0636\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 3.67397\n",
      "Epoch 23/1000\n",
      "292618/292618 [==============================] - 172s 588us/step - loss: 3.3936 - acc: 0.0666 - val_loss: 3.6984 - val_acc: 0.0621\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 3.67397\n",
      "Epoch 24/1000\n",
      "292618/292618 [==============================] - 172s 588us/step - loss: 3.3862 - acc: 0.0672 - val_loss: 3.6580 - val_acc: 0.0626\n",
      "\n",
      "Epoch 00024: val_loss improved from 3.67397 to 3.65800, saving model to ModelWeights/LSTM_Classical.h5\n",
      "Epoch 25/1000\n",
      "292618/292618 [==============================] - 172s 588us/step - loss: 3.3767 - acc: 0.0672 - val_loss: 3.6872 - val_acc: 0.0625\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.65800\n",
      "Epoch 26/1000\n",
      "292618/292618 [==============================] - 172s 588us/step - loss: 3.3674 - acc: 0.0671 - val_loss: 3.6836 - val_acc: 0.0646\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 3.65800\n",
      "Epoch 27/1000\n",
      "292618/292618 [==============================] - 172s 588us/step - loss: 3.3596 - acc: 0.0676 - val_loss: 3.6686 - val_acc: 0.0600\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 3.65800\n",
      "Epoch 28/1000\n",
      "292618/292618 [==============================] - 172s 588us/step - loss: 3.3508 - acc: 0.0676 - val_loss: 3.6677 - val_acc: 0.0633\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 3.65800\n",
      "Epoch 29/1000\n",
      "292618/292618 [==============================] - 172s 588us/step - loss: 3.3457 - acc: 0.0684 - val_loss: 3.6721 - val_acc: 0.0649\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 3.65800\n",
      "Epoch 30/1000\n",
      "292618/292618 [==============================] - 172s 588us/step - loss: 3.3361 - acc: 0.0686 - val_loss: 3.6764 - val_acc: 0.0659\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3.65800\n",
      "Epoch 31/1000\n",
      "292618/292618 [==============================] - 172s 588us/step - loss: 3.3309 - acc: 0.0691 - val_loss: 3.6855 - val_acc: 0.0637\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 3.65800\n",
      "Epoch 32/1000\n",
      "292618/292618 [==============================] - 172s 588us/step - loss: 3.3234 - acc: 0.0692 - val_loss: 3.6686 - val_acc: 0.0654\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 3.65800\n",
      "Epoch 33/1000\n",
      "292618/292618 [==============================] - 172s 588us/step - loss: 3.3161 - acc: 0.0691 - val_loss: 3.6958 - val_acc: 0.0660\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 3.65800\n",
      "Epoch 34/1000\n",
      "292618/292618 [==============================] - 172s 589us/step - loss: 3.3106 - acc: 0.0698 - val_loss: 3.6791 - val_acc: 0.0643\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.65800\n",
      "Epoch 00034: early stopping\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', verbose = 1, patience=10, min_delta = .00075)\n",
    "model_checkpoint = ModelCheckpoint(f'ModelWeights/LSTM_{model_type}.h5', verbose = 1, save_best_only=True,\n",
    "                                  monitor = 'val_loss')\n",
    "\n",
    "batch = 128 \n",
    "epochs = 1000 \n",
    "callbacks = [early_stopping, model_checkpoint]\n",
    "\n",
    "unique_n = len(notes_dict)\n",
    "# lstm_model = get_lstm(unique_n)\n",
    "\n",
    "#if you want to train from before\n",
    "lstm_model = load_model(f'ModelWeights/LSTM_{model_type}.h5')\n",
    "\n",
    "lstm_history = lstm_model.fit(x_train, y_train, batch_size = batch, epochs = epochs, validation_data = (x_test, y_test), \n",
    "                        callbacks = callbacks)\n",
    "\n",
    "pickle.dump(lstm_history, open(f'ModelPerf/{model_type}.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.save_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.system(r'%windir%\\system32\\rundll32.exe powrprof.dll,SetSuspendState Hibernate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MusicGenerator",
   "language": "python",
   "name": "musicgenerator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
